{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4d2dc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9628ef",
   "metadata": {},
   "source": [
    "Created ClaimFrequancy to get the expected number of claims per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe853202",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('claims_train.csv')\n",
    "df['ClaimFrequency'] = df['ClaimNb'] / df['Exposure']\n",
    "df = pd.read_csv('claims_train.csv')\n",
    "df['ClaimFrequency'] = df['ClaimNb'] / df['Exposure']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd26802",
   "metadata": {},
   "source": [
    "Remove outliers. Without it we would have ClaimFrequancy values of 732"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eaa69bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[df['Exposure'] >= 0.01]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f02ac90",
   "metadata": {},
   "source": [
    "Added a cap to ClaimFrequancy so we can avoid values of 366 ClaimFrequancies in a year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01f4ebe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDpol</th>\n",
       "      <th>ClaimNb</th>\n",
       "      <th>Exposure</th>\n",
       "      <th>Area</th>\n",
       "      <th>VehPower</th>\n",
       "      <th>VehAge</th>\n",
       "      <th>DrivAge</th>\n",
       "      <th>BonusMalus</th>\n",
       "      <th>VehBrand</th>\n",
       "      <th>VehGas</th>\n",
       "      <th>Density</th>\n",
       "      <th>Region</th>\n",
       "      <th>ClaimFrequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2122523.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.43</td>\n",
       "      <td>D</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>36</td>\n",
       "      <td>95</td>\n",
       "      <td>B1</td>\n",
       "      <td>Regular</td>\n",
       "      <td>1054</td>\n",
       "      <td>R24</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3173420.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>D</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>80</td>\n",
       "      <td>95</td>\n",
       "      <td>B2</td>\n",
       "      <td>Regular</td>\n",
       "      <td>598</td>\n",
       "      <td>R25</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1188619.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>E</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "      <td>76</td>\n",
       "      <td>B6</td>\n",
       "      <td>Regular</td>\n",
       "      <td>4172</td>\n",
       "      <td>R82</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31400.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.56</td>\n",
       "      <td>A</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>73</td>\n",
       "      <td>52</td>\n",
       "      <td>B13</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>15</td>\n",
       "      <td>R24</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3138755.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>E</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>50</td>\n",
       "      <td>B11</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>3021</td>\n",
       "      <td>R53</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       IDpol  ClaimNb  Exposure Area  VehPower  VehAge  DrivAge  BonusMalus  \\\n",
       "0  2122523.0        0      0.43    D         7      18       36          95   \n",
       "1  3173420.0        0      0.10    D         7      17       80          95   \n",
       "2  1188619.0        0      0.33    E         7       3       36          76   \n",
       "3    31400.0        0      0.56    A         5       4       73          52   \n",
       "4  3138755.0        0      0.27    E         8       0       37          50   \n",
       "\n",
       "  VehBrand   VehGas  Density Region  ClaimFrequency  \n",
       "0       B1  Regular     1054    R24             0.0  \n",
       "1       B2  Regular      598    R25             0.0  \n",
       "2       B6  Regular     4172    R82             0.0  \n",
       "3      B13   Diesel       15    R24             0.0  \n",
       "4      B11   Diesel     3021    R53             0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap = df['ClaimFrequency'].quantile(0.995)\n",
    "df['ClaimFrequency'] = df['ClaimFrequency'].clip(upper=cap)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25e6a5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE: 0.819263848833977\n"
     ]
    }
   ],
   "source": [
    "num_cols = ['VehPower', 'VehAge', 'DrivAge', 'BonusMalus', 'Density']\n",
    "cat_cols = ['Area']\n",
    "\n",
    "df_dummies = pd.get_dummies(df[cat_cols], drop_first=False)\n",
    "\n",
    "X_train = pd.concat([df[num_cols], df_dummies], axis=1).values\n",
    "y_train = df['ClaimFrequency'].values\n",
    "\n",
    "\n",
    "class decisionTree:\n",
    "    def __init__(self, min_samples_leaf=100, min_samples_split=20, max_depth=5):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.tree = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        X = np.asarray(X)\n",
    "        y = np.asarray(y)\n",
    "        self.tree = self.buildTree(X, y, 0)\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.asarray(X)\n",
    "        return np.array([self.predict_row(row, self.tree) for row in X])\n",
    "\n",
    "    def mse(self, y):\n",
    "        return ((y-y.mean())**2).mean()\n",
    "\n",
    "    def buildTree(self, X, y, depth):\n",
    "        n_samples, n_features = X.shape\n",
    "        node = {}\n",
    "        node[\"value\"] = float(y.mean())\n",
    "\n",
    "        best_loss = np.inf\n",
    "        best_thresh = None\n",
    "        best_feat = None\n",
    "\n",
    "        if (depth >= self.max_depth or\n",
    "            n_samples < self.min_samples_split or\n",
    "            np.unique(y).size == 1):\n",
    "            node['is_leaf'] = True\n",
    "            return node\n",
    "\n",
    "        for feat_idx in range(n_features):\n",
    "            values = X[:, feat_idx]\n",
    "            unique_vals = np.unique(values)\n",
    "            if unique_vals.size == 1:\n",
    "                continue\n",
    "            trashholds = (unique_vals[:-1] + unique_vals[1:]) / 2\n",
    "            for t in trashholds:\n",
    "                left_mask = values <= t\n",
    "                right_mask = ~left_mask\n",
    "\n",
    "                n_left = left_mask.sum()\n",
    "                n_right = right_mask.sum()\n",
    "\n",
    "                if n_left < self.min_samples_leaf or n_right < self.min_samples_leaf:\n",
    "                    continue\n",
    "                \n",
    "                y_left = y[left_mask]\n",
    "                y_right = y[right_mask]\n",
    "\n",
    "                mse_left = self.mse(y_left)\n",
    "                mse_right = self.mse(y_right)\n",
    "\n",
    "                loss = (n_left * mse_left + n_right * mse_right) / (n_samples)\n",
    "\n",
    "                if loss < best_loss:\n",
    "                    best_loss = loss\n",
    "                    best_thresh = t\n",
    "                    best_feat = feat_idx\n",
    "        \n",
    "        if best_feat is None:\n",
    "            node['is_leaf'] = True\n",
    "            return node\n",
    "\n",
    "        node['is_leaf'] = False\n",
    "        node['feature_index'] = best_feat\n",
    "        node['threshold'] = best_thresh\n",
    "\n",
    "        values = X[:, best_feat]\n",
    "        left_mask = values <= best_thresh\n",
    "        right_mask = ~left_mask\n",
    "\n",
    "        node['left'] = self.buildTree(X[left_mask], y[left_mask], depth + 1)\n",
    "        node['right'] = self.buildTree(X[right_mask], y[right_mask], depth + 1)\n",
    "\n",
    "        return node\n",
    "\n",
    "    def predict_row(self, row, node):\n",
    "        while not node['is_leaf']:\n",
    "            feat_idx = node['feature_index']\n",
    "            thresh = node['threshold']\n",
    "            if row[feat_idx] <= thresh:\n",
    "                node = node['left']\n",
    "            else:\n",
    "                node = node['right']\n",
    "        return node['value']\n",
    "\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    return np.sqrt(((y_true - y_pred) ** 2).mean())\n",
    "\n",
    "tree = decisionTree(\n",
    "    max_depth=12,\n",
    "    min_samples_split=200,\n",
    "    min_samples_leaf=10,\n",
    ")\n",
    "\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = tree.predict(X_train)\n",
    "\n",
    "print('Training RMSE:', rmse(y_train, y_train_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c273f56e",
   "metadata": {},
   "source": [
    "RMSE by area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ec60adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE by Area:\n",
      "Area A: 0.7203\n",
      "Area B: 0.7639\n",
      "Area C: 0.7837\n",
      "Area D: 0.8534\n",
      "Area E: 0.8900\n",
      "Area F: 1.0606\n"
     ]
    }
   ],
   "source": [
    "y_pred = tree.predict(X_train)\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    return np.sqrt(((y_true - y_pred) ** 2).mean())\n",
    "\n",
    "areas = df['Area'].unique()\n",
    "\n",
    "print(\"RMSE by Area:\")\n",
    "for a in sorted(areas):\n",
    "    mask = (df['Area'] == a)\n",
    "    area_rmse = rmse(y_train[mask], y_pred[mask])\n",
    "    print(f\"Area {a}: {area_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6403429",
   "metadata": {},
   "source": [
    "RMSE by density quartile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb674b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RMSE by Density Quartile:\n",
      "Q1: 0.7370\n",
      "Q2: 0.7871\n",
      "Q3: 0.8244\n",
      "Q4: 0.9184\n"
     ]
    }
   ],
   "source": [
    "df['DensityQuartile'] = pd.qcut(df['Density'], 4, labels=['Q1', 'Q2', 'Q3', 'Q4'])\n",
    "print(\"\\nRMSE by Density Quartile:\")\n",
    "for q in ['Q1', 'Q2', 'Q3', 'Q4']:\n",
    "    mask = (df['DensityQuartile'] == q)\n",
    "    quartile_rmse = rmse(y_train[mask], y_pred[mask])\n",
    "    print(f\"{q}: {quartile_rmse:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f69a0b",
   "metadata": {},
   "source": [
    "M2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5217b54b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((542410, 12), (135603, 12))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "ROOT = Path(\".\")  # adjust if needed\n",
    "train_path = ROOT / \"claims_train.csv\"\n",
    "test_path  = ROOT / \"claims_test.csv\"\n",
    "\n",
    "df_train = pd.read_csv(train_path)\n",
    "df_test  = pd.read_csv(test_path)\n",
    "\n",
    "# Target variable: ClaimFrequency = ClaimNb / Exposure\n",
    "for df in [df_train, df_test]:\n",
    "    df[\"ClaimFrequency\"] = df[\"ClaimNb\"] / df[\"Exposure\"]\n",
    "\n",
    "# Optional: filter tiny exposures, cap extreme frequencies as you already did\n",
    "min_exposure = 1e-3\n",
    "for name in [\"train\", \"test\"]:\n",
    "    if name == \"train\":\n",
    "        df_train = df_train[df_train[\"Exposure\"] > min_exposure].copy()\n",
    "    else:\n",
    "        df_test = df_test[df_test[\"Exposure\"] > min_exposure].copy()\n",
    "\n",
    "q = df_train[\"ClaimFrequency\"].quantile(0.995)\n",
    "df_train[\"ClaimFrequency\"] = df_train[\"ClaimFrequency\"].clip(upper=q)\n",
    "df_test[\"ClaimFrequency\"]  = df_test[\"ClaimFrequency\"].clip(upper=q)\n",
    "\n",
    "# ---- Choose features ----\n",
    "num_cols = [\"VehPower\", \"VehAge\", \"DrivAge\", \"BonusMalus\", \"Density\", \"Exposure\"]\n",
    "cat_cols = [\"Area\"]   # keep it simple, but you can add more later\n",
    "\n",
    "# One-hot encode categorical features\n",
    "train_dummies = pd.get_dummies(df_train[cat_cols], drop_first=False)\n",
    "test_dummies  = pd.get_dummies(df_test[cat_cols],  drop_first=False)\n",
    "\n",
    "# Align columns so train & test match exactly\n",
    "train_dummies, test_dummies = train_dummies.align(test_dummies, join=\"left\", axis=1, fill_value=0)\n",
    "\n",
    "X_train_df = pd.concat([df_train[num_cols], train_dummies], axis=1)\n",
    "X_test_df  = pd.concat([df_test[num_cols],  test_dummies],  axis=1)\n",
    "\n",
    "y_train = df_train[\"ClaimFrequency\"].values.astype(np.float64)\n",
    "y_test  = df_test[\"ClaimFrequency\"].values.astype(np.float64)\n",
    "\n",
    "X_train = X_train_df.values.astype(np.float64)\n",
    "X_test  = X_test_df.values.astype(np.float64)\n",
    "\n",
    "# Standardize features (very important for NN)\n",
    "X_mean = X_train.mean(axis=0, keepdims=True)\n",
    "X_std  = X_train.std(axis=0, keepdims=True) + 1e-8\n",
    "\n",
    "X_train_std = (X_train - X_mean) / X_std\n",
    "X_test_std  = (X_test  - X_mean) / X_std\n",
    "\n",
    "X_train_std.shape, X_test_std.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b6daa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class FFNNRegressor:\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim,\n",
    "        hidden_dim=32,\n",
    "        lr=0.01,\n",
    "        epochs=80,\n",
    "        batch_size=2048,\n",
    "        l2=0.0,\n",
    "        random_state=0,\n",
    "        verbose=True,\n",
    "    ):\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.l2 = l2\n",
    "        self.verbose = verbose\n",
    "\n",
    "        rng = np.random.RandomState(random_state)\n",
    "\n",
    "        self.W1 = rng.randn(input_dim, hidden_dim) / np.sqrt(input_dim)\n",
    "        self.b1 = np.zeros((1, hidden_dim))\n",
    "\n",
    "        self.W2 = rng.randn(hidden_dim, 1) / np.sqrt(hidden_dim)\n",
    "        self.b2 = np.zeros((1, 1))\n",
    "\n",
    "    @staticmethod\n",
    "    def relu(z):\n",
    "        return np.maximum(0.0, z)\n",
    "\n",
    "    @staticmethod\n",
    "    def relu_deriv(z):\n",
    "        return (z > 0.0).astype(np.float64)\n",
    "\n",
    "    @staticmethod\n",
    "    def mse(y_true, y_pred):\n",
    "        y_true = y_true.reshape(-1, 1)\n",
    "        y_pred = y_pred.reshape(-1, 1)\n",
    "        return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "    @staticmethod\n",
    "    def rmse(y_true, y_pred):\n",
    "        return np.sqrt(FFNNRegressor.mse(y_true, y_pred))\n",
    "\n",
    "    @staticmethod\n",
    "    def r2_score(y_true, y_pred):\n",
    "        y_true = y_true.reshape(-1)\n",
    "        y_pred = y_pred.reshape(-1)\n",
    "        ss_res = np.sum((y_true - y_pred) ** 2)\n",
    "        ss_tot = np.sum((y_true - y_true.mean()) ** 2)\n",
    "        return 1.0 - ss_res / ss_tot\n",
    "\n",
    "    def _forward(self, X):\n",
    "        \"\"\"\n",
    "        X: (batch_size, input_dim)\n",
    "        Returns (z1, a1, z2, y_pred)\n",
    "        \"\"\"\n",
    "        z1 = X @ self.W1 + self.b1\n",
    "        a1 = self.relu(z1)\n",
    "        z2 = a1 @ self.W2 + self.b2\n",
    "        y_pred = z2\n",
    "        return z1, a1, z2, y_pred\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        X: (N, D), y: (N,)\n",
    "        \"\"\"\n",
    "        X = np.asarray(X, dtype=np.float64)\n",
    "        y = np.asarray(y, dtype=np.float64).reshape(-1, 1)\n",
    "        N, D = X.shape\n",
    "        assert D == self.input_dim, \"input_dim mismatch\"\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            idx = np.random.permutation(N)\n",
    "            X_shuffled = X[idx]\n",
    "            y_shuffled = y[idx]\n",
    "\n",
    "            for start in range(0, N, self.batch_size):\n",
    "                end = start + self.batch_size\n",
    "                X_batch = X_shuffled[start:end]\n",
    "                y_batch = y_shuffled[start:end]\n",
    "                if X_batch.shape[0] == 0:\n",
    "                    continue\n",
    "\n",
    "                z1, a1, z2, y_pred = self._forward(X_batch)\n",
    "\n",
    "                batch_size = X_batch.shape[0]\n",
    "                dL_dy = 2.0 * (y_pred - y_batch) / batch_size \n",
    "\n",
    "                dL_dW2 = a1.T @ dL_dy\n",
    "                dL_db2 = np.sum(dL_dy, axis=0, keepdims=True) \n",
    "\n",
    "                if self.l2 > 0.0:\n",
    "                    dL_dW2 += 2.0 * self.l2 * self.W2\n",
    "\n",
    "                dL_da1 = dL_dy @ self.W2.T\n",
    "                dL_dz1 = dL_da1 * self.relu_deriv(z1)\n",
    "\n",
    "                dL_dW1 = X_batch.T @ dL_dz1\n",
    "                dL_db1 = np.sum(dL_dz1, axis=0, keepdims=True)\n",
    "\n",
    "                if self.l2 > 0.0:\n",
    "                    dL_dW1 += 2.0 * self.l2 * self.W1\n",
    "\n",
    "                self.W2 -= self.lr * dL_dW2\n",
    "                self.b2 -= self.lr * dL_db2\n",
    "                self.W1 -= self.lr * dL_dW1\n",
    "                self.b1 -= self.lr * dL_db1\n",
    "\n",
    "            if self.verbose and (epoch % 10 == 0 or epoch == self.epochs - 1):\n",
    "                _, _, _, y_pred_full = self._forward(X)\n",
    "                loss = self.mse(y, y_pred_full)\n",
    "                rmse_val = self.rmse(y, y_pred_full)\n",
    "                print(f\"Epoch {epoch+1:3d}/{self.epochs} - MSE: {loss:.6f} - RMSE: {rmse_val:.4f}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.asarray(X, dtype=np.float64)\n",
    "        _, _, _, y_pred = self._forward(X)\n",
    "        return y_pred.ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19361a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1/80 - MSE: 0.804691 - RMSE: 0.8970\n",
      "Epoch  11/80 - MSE: 0.789238 - RMSE: 0.8884\n",
      "Epoch  21/80 - MSE: 0.788333 - RMSE: 0.8879\n",
      "Epoch  31/80 - MSE: 0.787965 - RMSE: 0.8877\n",
      "Epoch  41/80 - MSE: 0.787829 - RMSE: 0.8876\n",
      "Epoch  51/80 - MSE: 0.787584 - RMSE: 0.8875\n",
      "Epoch  61/80 - MSE: 0.787412 - RMSE: 0.8874\n",
      "Epoch  71/80 - MSE: 0.787209 - RMSE: 0.8872\n",
      "Epoch  80/80 - MSE: 0.787139 - RMSE: 0.8872\n",
      "\n",
      "Scratch NN (M2) performance:\n",
      "Train RMSE: 0.8872\n",
      "Test  RMSE: 0.8881\n",
      "Train R²:   0.0107\n",
      "Test  R²:   0.0104\n"
     ]
    }
   ],
   "source": [
    "input_dim = X_train_std.shape[1]\n",
    "\n",
    "nn = FFNNRegressor(\n",
    "    input_dim=input_dim,\n",
    "    hidden_dim=32,\n",
    "    lr=0.01,\n",
    "    epochs=80,\n",
    "    batch_size=2048,\n",
    "    l2=1e-4,\n",
    "    random_state=42,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "nn.fit(X_train_std, y_train)\n",
    "\n",
    "y_pred_train = nn.predict(X_train_std)\n",
    "y_pred_test  = nn.predict(X_test_std)\n",
    "\n",
    "print(\"\\nScratch NN (M2) performance:\")\n",
    "print(f\"Train RMSE: {nn.rmse(y_train, y_pred_train):.4f}\")\n",
    "print(f\"Test  RMSE: {nn.rmse(y_test,  y_pred_test):.4f}\")\n",
    "print(f\"Train R²:   {nn.r2_score(y_train, y_pred_train):.4f}\")\n",
    "print(f\"Test  R²:   {nn.r2_score(y_test,  y_pred_test):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
